{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "%sql postgresql://borisbastian:boris@localhost:5432/boris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    data_xls = pd.read_excel(file, sheet_name=0, index_col=None, skiprows=4, header=1)\n",
    "    data_xls.to_csv(file[:-4]+'_out.csv', encoding='utf-8',index=False)\n",
    "    #index false removes the row index column that pd.read_excel adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import csv, uuid, glob, datetime\n",
    "path='/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/'\n",
    "\n",
    "def twriter(file,lol):\n",
    "    with open(path+file,'w', newline='') as fo2:\n",
    "        csv_writer = csv.writer(fo2, delimiter=',') \n",
    "        for n in lol:\n",
    "            csv_writer.writerow(n)\n",
    "\n",
    "def validate(date_text):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "        correct_date=True\n",
    "    except ValueError:\n",
    "        correct_date=False\n",
    "    return correct_date\n",
    "            \n",
    "def emptyrow(row):\n",
    "    a=''\n",
    "    for key in row:\n",
    "        a=a+row[key]\n",
    "        if a.strip() =='':\n",
    "            emptyrow=True\n",
    "        else:\n",
    "            emptyrow=False\n",
    "    return (emptyrow)\n",
    "\n",
    "def get_fields(row, fields):\n",
    "    extract = {key: row[key] for key in row.keys() & set(fields)} \n",
    "    for key in fields:\n",
    "        extract[key] = extract.pop(key)\n",
    "        #this is necessary to create an ordered list of the dictionary generated above\n",
    "    return [ v for v in extract.values() ]\n",
    "    #this makes a list out of the values in the ordered dictionary\n",
    "\n",
    "#Define row labels to be extracted for each destination table\n",
    "pat_fields=['Name', 'DOB', 'SSN','MRN','Gender']\n",
    "block_fields=['DeptNumber', 'CombinedName', 'SpecID','RefPhy',\\\n",
    "            'Site Description','DiagnosisCode','Diagnosis Description','Diagnosis Text',\\\n",
    "            'Clinical','Gross','Micro','SpecNoteText']\n",
    "dx_fields=['DeptNumber','SpecID', 'DiagnosisCode']\n",
    "doc_fields=['RefPhy','Address1','Address2','City','State','Zip']\n",
    "special_fields=['DeptNumber','SpecID','F8 Orders','CPT']\n",
    "pat_table = [['dummy','dummy','dummy','dummy']] #fake initiating patient\n",
    "block_table = []\n",
    "dx_table = []\n",
    "doc_table = []\n",
    "specials_table = []\n",
    "dx_table=[]\n",
    "pat_id=str(uuid.uuid4()) # is used for the very first patient\n",
    "csv_files=glob.glob(path+'/**/*.csv', recursive = True)\n",
    "for source_file in csv_files:\n",
    "    rowcount=0\n",
    "    with open(source_file, 'r') as read_obj:\n",
    "        # pass the file object to DictReader() to get the DictReader object\n",
    "        csv_dict_reader = DictReader(read_obj)\n",
    "        # iterate over each line as a ordered dictionary\n",
    "        print(source_file)\n",
    "        \n",
    "        for row in csv_dict_reader:\n",
    "            # row variable is a dictionary that represents a row in csv\n",
    "            #print(row)\n",
    "            if emptyrow(row):\n",
    "                continue\n",
    "                #tests whether a row is empty and skips it\n",
    "            block=get_fields(row, block_fields)\n",
    "            patient=get_fields(row, pat_fields)\n",
    "            \n",
    "            \n",
    "            if block[0]!='':\n",
    "                block_id=block[0]+block[2]\n",
    "                #don't overwrite a block_id or patient_id if there are no entries\n",
    "                #i.e. this is a row with only F8 orders or dx codes\n",
    "            \n",
    "            doc=get_fields(row, doc_fields)\n",
    "            \n",
    "            \n",
    "            specials=get_fields(row, special_fields)\n",
    "            specials.insert(0,block_id)\n",
    "            \n",
    "            dx=get_fields(row, dx_fields)\n",
    "            \n",
    "            if row['F8 Orders']!='':\n",
    "                specials_table.append(specials)\n",
    "            if row['Name']!='':\n",
    "                if patient[0:2]!=pat_table[-1][1:3]: \n",
    "                    # compares the patient name + dob to that of last entry\n",
    "                    # if different, this is a new patient\n",
    "                    #print(patient[0:2], pat_table[-1][1:3])\n",
    "                    pat_id=str(uuid.uuid4())\n",
    "#                 if len(patient[1])>10:\n",
    "#                     patient[1]=patient[1][:10]\n",
    "#                     # some DOB entries come in date time format such as 1960-07-02 00:00:00\n",
    "#                     # this cuts off after the day\n",
    "#                 dob = patient[1]\n",
    "#                 dob = pd.to_datetime(dob, infer_datetime_format=True)\n",
    "#                 dob = dob.date()\n",
    "                patient[1]=patient[1][:10] #trims >10 letters from dob\n",
    "                if not validate(patient[1]): \n",
    "                    patient[1]='1000-01-01' # replaces incorrect dob \n",
    "                patient.insert(0, pat_id) #would take 'old' pat_id for not new patient\n",
    "                doc.insert(0,block_id)\n",
    "                dx.insert(0,block_id)\n",
    "                #write everything into lols\n",
    "                pat_table.append(patient)\n",
    "                block_table.append(block)\n",
    "                dx_table.append(dx)\n",
    "                doc_table.append(doc)\n",
    "            elif row['DiagnosisCode']!='':\n",
    "                dx.insert(0,block_id)\n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "#             print(\"Patient\",patient.values())\n",
    "#             print(\"Block\",block)\n",
    "#             print(\"Doc\",doc)\n",
    "#             print(\"Specials\",specials)\n",
    "#             print(\"Secondaries\",secondaries)\n",
    "#             rowcount+=1\n",
    "#             if rowcount>10:\n",
    "# #                 print(patient)\n",
    "# #                 print(block_table)\n",
    "#                 break\n",
    "#print(pat_table)\n",
    "# print(block_table)\n",
    "# print(dx_table)\n",
    "twriter('IP_patients.txt',pat_table[1:])#slices off dummy row\n",
    "twriter('IP_blocks.txt',block_table)\n",
    "twriter('IP_doc.txt',doc_table)\n",
    "twriter('IP_specials.txt',specials_table)\n",
    "twriter('IP_dx.txt',dx_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "drop table if exists ip_pats;\n",
    "create table ip_pats(\n",
    "    pat_id text,\n",
    "    name text,\n",
    "    dob date,\n",
    "    ssn text,\n",
    "    mrn text,\n",
    "    gender text\n",
    ");\n",
    "drop table if exists ip_blocks;\n",
    "create table ip_blocks(\n",
    "    block_id text,\n",
    "    dept_number text,\n",
    "    combined_bame text,\n",
    "    spec_id varchar(1),\n",
    "    ref_phy text,\n",
    "    site text,\n",
    "    dx_code text,\n",
    "    dx_descr text,\n",
    "    dx_text text,\n",
    "    clinical text,\n",
    "    gross text,\n",
    "    micro text,\n",
    "    note text\n",
    ");\n",
    "drop table if exists ip_docs;\n",
    "create table ip_docs(\n",
    "    block_id text,\n",
    "    ref_phy text,\n",
    "    address1 text,\n",
    "    address2 text,\n",
    "    city text,\n",
    "    state text,\n",
    "    zip text\n",
    ");\n",
    "drop table if exists ip_dx;\n",
    "create table ip_dx(\n",
    "    block_id text,\n",
    "    dept_number text,\n",
    "    spec_id varchar(1),\n",
    "    dx_code text\n",
    ");\n",
    "drop table if exists ip_specials;\n",
    "create table ip_specials(\n",
    "    block_id text,\n",
    "    dept_number text,\n",
    "    spec_id varchar(1),\n",
    "    f8_order text,\n",
    "    cpt text\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "copy ip_pats from '/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/IP_patients.txt' with (format CSV); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:labDB2] *",
   "language": "python",
   "name": "conda-env-labDB2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
