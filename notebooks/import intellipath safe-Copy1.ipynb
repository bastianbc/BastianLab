{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: borisbastian@boris'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2, glob, csv, uuid, datetime\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "%sql postgresql://borisbastian:boris@localhost:5432/boris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps\n"
     ]
    }
   ],
   "source": [
    "cd {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (17736373) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (16719306) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (17775387) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (20095896) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (15620737) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (17196739) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (19345193) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (16538767) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "file_list=glob.glob(path+'/**/*.xls', recursive = True)\n",
    "for file in file_list:\n",
    "    data_xls = pd.read_excel(file, sheet_name=0, index_col=None, skiprows=4, header=1)\n",
    "    data_xls.to_csv(file[:-4]+'_out.csv', encoding='utf-8',index=False)\n",
    "    #index false removes the row index column that pd.read_excel adds\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/8-August2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/7-July2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/11-Nov2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/10-Oct2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/5-May2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/9-Sept2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/1-Jan2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/2-Feb2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/4-April2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/12-Dec2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/3-Mar2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2015/6-June2015_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/9-Sept2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/5-May2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/1-Jan2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/8-August2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/3-March2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/10-Oct2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/7-July2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/11-Nov2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/6-June2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/12-Dec2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/4-April2016_out.csv\n",
      "READING: /Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/2016/2-Feb2016_out.csv\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "path='/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/'\n",
    "\n",
    "def twriter(file,lol):\n",
    "    with open(path+file,'w', newline='') as fo2:\n",
    "        csv_writer = csv.writer(fo2, delimiter=',') \n",
    "        for n in lol:\n",
    "            csv_writer.writerow(n)\n",
    "\n",
    "def validate(date_text):\n",
    "    try:\n",
    "        datetime.datetime.strptime(date_text, '%Y-%m-%d')\n",
    "        correct_date=True\n",
    "    except ValueError:\n",
    "        correct_date=False\n",
    "    return correct_date\n",
    "            \n",
    "def emptyrow(row):\n",
    "    a=''\n",
    "    for key in row:\n",
    "        a=a+row[key]\n",
    "        if a.strip() =='':\n",
    "            emptyrow=True\n",
    "        else:\n",
    "            emptyrow=False\n",
    "    return (emptyrow)\n",
    "\n",
    "def get_fields(row, fields):\n",
    "    extract = {key: row[key] for key in row.keys() & set(fields)} \n",
    "    for key in fields:\n",
    "        extract[key] = extract.pop(key)\n",
    "        #this is necessary to create an ordered list of the dictionary generated above\n",
    "    return [ v for v in extract.values() ]\n",
    "    #this makes a list out of the values in the ordered dictionary\n",
    "\n",
    "#Define row labels to be extracted for each destination table\n",
    "pat_fields=['Name', 'DOB', 'SSN','MRN','Gender']\n",
    "block_fields=['DeptNumber', 'CombinedName', 'SpecID','RefPhy',\\\n",
    "            'Site Description','DiagnosisCode','Diagnosis Description','Diagnosis Text',\\\n",
    "            'Clinical','Gross','Micro','SpecNoteText']\n",
    "#dx_fields=['DeptNumber','SpecID', 'DiagnosisCode']\n",
    "doc_fields=['RefPhy','Address1','Address2','City','State','Zip']\n",
    "special_fields=['DeptNumber','SpecID','F8 Orders','CPT']\n",
    "pat_table = [['dummy','dummy','dummy','dummy']] #fake initiating patient\n",
    "block_table = []\n",
    "dx_table = []\n",
    "doc_table = []\n",
    "specials_table = []\n",
    "dx_table=[]\n",
    "pat_id=str(uuid.uuid4()) # is used for the very first patient\n",
    "csv_files=glob.glob(path+'/**/*.csv', recursive = True)\n",
    "# gets a list of all csv files in current dir and subdirs\n",
    "for source_file in csv_files:\n",
    "    with open(source_file, 'r') as read_obj:\n",
    "        # pass the file object to DictReader() to get the DictReader object\n",
    "        csv_dict_reader = DictReader(read_obj)\n",
    "        # iterate over each line as a ordered dictionary\n",
    "        print('READING:',source_file)\n",
    "        \n",
    "        for row in csv_dict_reader:\n",
    "            # row variable is a dictionary that represents a row in csv\n",
    "            #print(row)\n",
    "            if emptyrow(row):\n",
    "                continue\n",
    "                #tests whether a row is empty and skips it\n",
    "            block=get_fields(row, block_fields)\n",
    "            patient=get_fields(row, pat_fields)\n",
    "            \n",
    "            \n",
    "            if block[0]!='':\n",
    "                block_id=block[0]+block[2]\n",
    "                #print(block)\n",
    "                #don't overwrite a block_id or patient_id if there are no entries\n",
    "                #i.e. this is a row with only F8 orders or dx codes\n",
    "            \n",
    "            doc=get_fields(row, doc_fields)\n",
    "            \n",
    "            \n",
    "            specials=get_fields(row, special_fields)\n",
    "            specials.insert(0,block_id)\n",
    "            \n",
    "            #dx=get_fields(row, dx_fields)\n",
    "            \n",
    "            if row['F8 Orders']!='':\n",
    "                specials_table.append(specials)\n",
    "            if row['Name']!='':\n",
    "                if patient[0:2]!=pat_table[-1][1:3]: \n",
    "                    # compares the patient name + dob to that of last entry\n",
    "                    # if different, this is a new patient\n",
    "                    #print(patient[0:2], pat_table[-1][1:3])\n",
    "                    pat_id=str(uuid.uuid4())\n",
    "                patient[1]=patient[1][:10] #trims >10 letters from dob\n",
    "                if not validate(patient[1]): \n",
    "                    patient[1]='1000-01-01' # replaces incorrect dob \n",
    "                patient.insert(0, pat_id) #would take 'old' pat_id for not new patient\n",
    "                doc.insert(0,block_id)\n",
    "                #dx.insert(0,block_id)\n",
    "                #write everything into lols\n",
    "                pat_table.append(patient)\n",
    "                #print(block)\n",
    "                block.insert(0,block_id)\n",
    "                block.insert(1,pat_id)\n",
    "                block_table.append(block)\n",
    "                #dx_table.append(dx)\n",
    "                doc_table.append(doc)\n",
    "twriter('IP_patients.txt',pat_table[1:])#slices off dummy row\n",
    "twriter('IP_blocks.txt',block_table)\n",
    "twriter('IP_doc.txt',doc_table)\n",
    "twriter('IP_specials.txt',specials_table)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DA15-73759A', '4f2f5d51-7440-44b9-8f6a-c067979c2dd6', 'DA15-73759', 'Mully, Thaddeus W.', 'A', 'KENNER, JULIE', 'FOREARM, LEFT', '80710', 'SCC', 'SQUAMOUS CELL CARCINOMA', '11 MM ERYTHMATOUS KERATOTIC PAP; R/O SCC VS. HAK VS. VV', 'One outside slide, CB15-0188 A.', 'There are irregularly shaped aggregations of squamous keratinocytes with atypical nuclei within the dermis. ', 'The neoplasm extends to the base of the specimen.']\n"
     ]
    }
   ],
   "source": [
    "print(block_table[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "drop table if exists ip_pats;\n",
    "create table ip_pats(\n",
    "    pat_id text,\n",
    "    name text,\n",
    "    dob date,\n",
    "    ssn text,\n",
    "    mrn text,\n",
    "    gender text\n",
    ");\n",
    "drop table if exists ip_blocks;\n",
    "create table ip_blocks(\n",
    "    block_id text,\n",
    "    pat_id text,\n",
    "    case_no text,\n",
    "    combined_name text,\n",
    "    spec text,\n",
    "    ref_phy text,\n",
    "    site text,\n",
    "    dx_code text,\n",
    "    dx_descr text,\n",
    "    dx_text text,\n",
    "    clinical text,\n",
    "    gross text,\n",
    "    micro text,\n",
    "    note text\n",
    ");\n",
    "drop table if exists ip_docs;\n",
    "create table ip_docs(\n",
    "    block_id text,\n",
    "    ref_phy text,\n",
    "    address1 text,\n",
    "    address2 text,\n",
    "    city text,\n",
    "    state text,\n",
    "    zip text\n",
    ");\n",
    "drop table if exists ip_specials;\n",
    "create table ip_specials(\n",
    "    block_id text,\n",
    "    dept_number text,\n",
    "    spec_id varchar(1),\n",
    "    f8_order text,\n",
    "    cpt text\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "404626 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy ip_pats from '/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/IP_patients.txt' with (format CSV); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "404626 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy ip_blocks from '/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/IP_blocks.txt' with (format CSV); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "206576 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy ip_specials from '/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/IP_specials.txt' with (format CSV); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "404626 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "copy ip_docs from '/Users/borisbastian/opt/anaconda3/envs/labDB2/data/intellipath_dumps/IP_doc.txt' with (format CSV); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE INDEX  pat_id_index  ON ip_pats \n",
    "(\n",
    "    pat_id\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE INDEX  name_dob_index  ON ip_pats \n",
    "(\n",
    "    name,\n",
    "    dob\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://borisbastian:***@localhost:5432/boris\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE INDEX  block_patid_index  ON ip_blocks \n",
    "(\n",
    "    pat_id\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH plan AS (\n",
    "   SELECT *\n",
    "   FROM  (\n",
    "      SELECT pat_id, min(pat_id) OVER (PARTITION BY name, dob) AS master_pat_id\n",
    "      FROM   ip_pats\n",
    "      ) sub\n",
    "   WHERE  pat_id <> master_pat_id  -- ... <> self\n",
    "   )\n",
    " , upd_ip_blocks AS (\n",
    "   UPDATE ip_blocks b\n",
    "   SET    b.pat_id = p.master_pat_id   -- link to master pat_id ...\n",
    "   FROM   plan p\n",
    "   WHERE  b.pat_id = p.pat_id\n",
    "   )\n",
    "DELETE FROM ip_pats\n",
    "USING  plan p\n",
    "WHERE  ip_apts.pat_id = p.pat_id\n",
    "RETURNING ip_pats.pat_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH plan AS (\n",
    "   SELECT *\n",
    "   FROM  (\n",
    "      SELECT recid, min(recid) OVER (PARTITION BY cdesc) AS master_recid\n",
    "      FROM   cpt\n",
    "      ) sub\n",
    "   WHERE  recid <> master_recid  -- ... <> self\n",
    "   )\n",
    " , upd_lab AS (\n",
    "   UPDATE lab l\n",
    "   SET    cpt_recid = p.master_recid   -- link to master recid ...\n",
    "   FROM   plan p\n",
    "   WHERE  l.cpt_recid = p.recid\n",
    "   )\n",
    "DELETE FROM cpt c\n",
    "USING  plan p\n",
    "WHERE  c.recid = p.recid\n",
    "RETURNING c.recid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:labDB2] *",
   "language": "python",
   "name": "conda-env-labDB2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
